# Resumo
Nesta sprint, aprendi sobre o framework de processamento de dados Apache Spark e realizei os laboratórios práticos de serviços da AWS.

# Exercícios

Nesta Sprint, realizei exercícios que exploraram:

1) Criação de um [script](./Exercicios/Contador-de-palavras-spark/contador.py) com pyspark para contar palavras.

A seguir as imagens da execução do exercício:

![imagem](./Exercicios/Contador-de-palavras-spark/baixarimagemjupyter.png)

![container](./Exercicios/Contador-de-palavras-spark/criar%20container.png)

![readme](./Exercicios/Contador-de-palavras-spark/copiarREADMEexecPySpark.png)

![lista](./Exercicios/Contador-de-palavras-spark/listaPalavras.png)

2) Extração de dados da API do TMDB com python:

[código aqui](./Exercicios/TMDB/api.py)

 - Criar a conta:

![etapa1](./Exercicios/TMDB/etapa1.png)

 - Fazer a consulta:

![etapa2](./Exercicios/TMDB/etapa2.png)

3) Construção de um processo de ETL simplificado, utilizando o serviço AWS Glue:

[Exemplo Glue](./Exercicios/Glue/exemplo.py)

 - script [Sua vez!](./Exercicios/Glue/gluelab.py)

 - Job:

 ![job](./Exercicios/Glue/job.png)

 - Log:

![log](./Exercicios/Glue/logs.png)

 - crawler:

![crawler](./Exercicios/Glue/Crawler.png)

![crawler1](./Exercicios/Glue/Crawler1.png)

![crawler2](./Exercicios/Glue/Crawler2.png)

![crawler3](./Exercicios/Glue/Crawler3.png)


# Desafio

Para acessar o desafio, clique [aqui](Desafio/README.md)

# Evidências

As evidências do desafio podem ser acessadas [aqui](Evidencias/)

# Certificados

Nesta sprint não foram ofertados cursos da AWS. 